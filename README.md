# üîß Tractian Knowledge Base - RAG System

A **Retrieval-Augmented Generation (RAG)** system that allows users to upload PDF documents and ask questions about their contents. Built with FastAPI, FAISS, and OpenAI.

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Flask       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ              FastAPI Backend              ‚îÇ
‚îÇ  Frontend    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                    ‚îÇ  ‚îÇ PDF Process  ‚îÇ   ‚îÇ  LLM Service     ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îÇ - Extract    ‚îÇ   ‚îÇ  - OpenAI GPT-5  ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îÇ - Chunk      ‚îÇ   ‚îÇ  - Prompt Eng.   ‚îÇ  ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                    ‚îÇ         ‚îÇ                    ‚îÇ             ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                    ‚îÇ  ‚îÇ          Vector Store (FAISS)         ‚îÇ ‚îÇ
                    ‚îÇ  ‚îÇ  - Embeddings (sentence-transformers) ‚îÇ ‚îÇ
                    ‚îÇ  ‚îÇ  - Cosine Similarity Search           ‚îÇ ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- OpenAI API key **and/or** Gemini API key
- Gemini Key

### 1. Clone & Install

```bash
git clone https://github.com/fabriciojesus/tractian-knowledge-base.git
cd Tractian_KB

# This will create a virtual environment and install dependencies
make install
```

### 2. Configure

```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY or GEMINI_API_KEY
```

### 3. Run

```bash
# Start the API
make run-api

# In another terminal, start the frontend
make run-frontend
```

- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Frontend**: http://localhost:8501

## üì° API Specification

### POST /documents

Upload PDF documents to be indexed.

```bash
curl -X POST "http://localhost:8000/documents" \
  -F "files=@document1.pdf" \
  -F "files=@document2.pdf"
```

**Response:**
```json
{
  "message": "Documents processed successfully",
  "documents_indexed": 2,
  "total_chunks": 128
}
```

### POST /question

Ask a question about uploaded documents.

```bash
curl -X POST "http://localhost:8000/question" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the power consumption of the motor?"}'
```

**Response:**
```json
{
  "answer": "The motor's power consumption is 2.3 kW.",
  "references": [
    "the motor xxx requires 2.3kw to operate at a 60hz line frequency"
  ]
}
```

### GET /health

Health check endpoint.

```bash
curl http://localhost:8000/health
```

## üê≥ Docker

```bash
# Build and start all services
make docker-build
make docker-up

# View logs
make docker-logs

# Stop
make docker-down
```

## üß™ Testing

```bash
# Run all tests with coverage
make test

# Run unit tests only
make test-unit

# Run API tests only
make test-api
```

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py        # API endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py        # Pydantic models
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ pdf_processor.py # PDF extraction & chunking
‚îÇ       ‚îú‚îÄ‚îÄ embeddings.py    # Embedding generation
‚îÇ       ‚îú‚îÄ‚îÄ vector_store.py  # ChromaDB operations
‚îÇ       ‚îî‚îÄ‚îÄ llm_service.py   # LLM integration
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py     # Streamlit UI
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py          # API integration tests
‚îÇ   ‚îî‚îÄ‚îÄ test_services.py     # Unit tests
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üîß Configuration

All configuration is managed via environment variables (`.env` file):

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | - | OpenAI API key |
| `OPENAI_MODEL` | `gpt-4o-mini` | OpenAI model to use |
| `GEMINI_API_KEY` | - | Gemini API key |
| `GEMINI_MODEL` | `gemini-1.5-flash` | Gemini model to use |
| `EMBEDDING_MODEL` | `all-MiniLM-L6-v2` | Sentence transformer model |
| `CHUNK_SIZE` | `1000` | Text chunk size in characters |
| `CHUNK_OVERLAP` | `200` | Overlap between chunks |
| `TOP_K_RESULTS` | `3` | Number of chunks for context |
| `LLM_TEMPERATURE` | `0.1` | LLM temperature (lower = more deterministic) |

### ü§ñ LLM Multi-Provider Support

This project supports two main providers. You can switch between them in the UI:

| Provider | Model | Cost | Recommendation |
| :--- | :--- | :--- | :--- |
| **Google Gemini** | `gemini-1.5-flash` | **Free Tier** available | Recommended for testing and free usage. |
| **OpenAI** | `gpt-4o-mini` | **Paid Only** (Credits required) | Use if you have an active billing account. |

> [!NOTE]
> If you see a `billing_not_active` error with OpenAI, it means your account has no credits or the API key is restricted. Switch to Gemini to continue for free.

## üß† Technical Decisions

### Why FAISS?
Facebook AI Similarity Search is extremely fast for vector similarity queries. Used with normalized vectors and inner product for cosine similarity. Persists to disk with JSON metadata ‚Äî no external server needed.

### Why sentence-transformers (all-MiniLM-L6-v2)?
Fast, lightweight embedding model with good multilingual support. Runs locally without API calls, reducing latency and cost.

### Why Recursive Character Text Splitter?
Preserves semantic meaning by splitting on natural boundaries (paragraphs ‚Üí sentences ‚Üí words). The 200-character overlap ensures context continuity across chunks.

### Why pdfplumber?
Superior text extraction compared to PyPDF2, especially for documents with tables, columns, and complex layouts ‚Äî common in industrial/engineering PDFs.

## üìù License

MIT
